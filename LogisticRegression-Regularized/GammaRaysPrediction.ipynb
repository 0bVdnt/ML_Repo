{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3483a5e7",
   "metadata": {},
   "source": [
    "# Logistic Regression to Classify Gamma-Ray Signals from background hadrons\n",
    "### Performing Logistic Regression on the MAGIC Gamma Telescope project dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6004b9",
   "metadata": {},
   "source": [
    "## Dataset Specifications\n",
    "### Features:\n",
    "- fLength: Major axis of the ellipse, measured in millimeters (continuous).\n",
    "- fWidth: Minor axis of the ellipse, measured in millimeters (continuous).\n",
    "- fSize: Logarithmic sum of the content of all pixels in the telescope's image (continuous).\n",
    "- fConc: Ratio of the sum of the two highest pixel values over the total size (continuous).\n",
    "- fConc1: Ratio of the highest pixel value over the total size (continuous).\n",
    "- fAsym: Distance from the highest pixel to the center of the ellipse, projected onto the major axis (continuous).\n",
    "- fM3Long: 3rd root of the third moment along the major axis, in millimeters (continuous).\n",
    "- fM3Trans: 3rd root of the third moment along the minor axis, in millimeters (continuous).\n",
    "- fAlpha: Angle of the major axis relative to the vector to the origin, in degrees (continuous).\n",
    "- fDist: Distance from the origin to the center of the ellipse, in millimeters (continuous).\n",
    "### class: Target variable, representing:\n",
    "- g: Gamma-ray signal (positive class).\n",
    "- h: Hadron noise (negative class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a02d453c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cf446549",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X, y, test_size=0.2, random_state=None):\n",
    "    \"\"\"\n",
    "    Split dataset into training and testing sets using NumPy.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : numpy array, shape (m_samples, n_features)\n",
    "        Feature dataset\n",
    "    y : numpy array, shape (m_samples,)\n",
    "        Target labels\n",
    "    test_size : float, default=0.2\n",
    "        Proportion of the dataset to include in the test split (between 0 and 1)\n",
    "    random_state : int or None, default=None\n",
    "        Random seed for reproducibility\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    X_train, X_test, y_train, y_test : numpy arrays\n",
    "        Split datasets\n",
    "    \"\"\"\n",
    "    if random_state is not None:\n",
    "        np.random.seed(random_state)\n",
    "    \n",
    "    # Shuffle indices\n",
    "    indices = np.random.permutation(len(X))\n",
    "    \n",
    "    # Determine split point\n",
    "    test_split = int(len(X) * test_size)\n",
    "    \n",
    "    # Split indices\n",
    "    test_indices = indices[:test_split]\n",
    "    train_indices = indices[test_split:]\n",
    "    \n",
    "    # Return split data\n",
    "    X_train, X_test = X[train_indices], X[test_indices]\n",
    "    y_train, y_test = y[train_indices], y[test_indices]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "13b7abce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_scaling(X):\n",
    "    \"\"\"\n",
    "    Scales features to have a mean of 0 and a standard deviation of 1.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : numpy array, shape (m_samples, n_features)\n",
    "        Feature dataset\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    X_scaled : numpy array, shape (m_samples, n_features)\n",
    "        Scaled feature dataset\n",
    "    mu : numpy array, shape (n_features,)\n",
    "        Mean of each feature\n",
    "    sigma : numpy array, shape (n_features,)\n",
    "        Standard deviation of each feature\n",
    "    \"\"\"\n",
    "    mu = np.mean(X, axis=0)\n",
    "    sigma = np.std(X, axis=0)\n",
    "    X_scaled = (X - mu) / sigma\n",
    "    return X_scaled, mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9a7cb30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training Set:\n",
      "Training Features: (15216, 10)\n",
      "Training Labels: (15216,)\n",
      "\n",
      "\n",
      "Testing Set:\n",
      "Testing Features: (3804, 10)\n",
      "Testing Labels: (3804,)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('magic-gemma-telescope.csv')\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.iloc[:, :-1].values, df.iloc[:, -1].values, 0.2, 42)\n",
    "\n",
    "print('\\n\\nTraining Set:')\n",
    "print('Training Features:', X_train.shape)\n",
    "print('Training Labels:', y_train.shape)\n",
    "print('\\n\\nTesting Set:')\n",
    "print('Testing Features:', X_test.shape)\n",
    "print('Testing Labels:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "85d4253f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Scaled Training Set:\n",
      "Scaled Training Features: (15216, 10)\n",
      "\n",
      "\n",
      "Scaled Testing Set:\n",
      "Scaled Testing Features: (3804, 10)\n"
     ]
    }
   ],
   "source": [
    "# Scale the features\n",
    "X_train_scaled, mu, sigma = feature_scaling(X_train)\n",
    "X_test_scaled = (X_test - mu) / sigma\n",
    "\n",
    "print('\\n\\nScaled Training Set:')\n",
    "print('Scaled Training Features:', X_train_scaled.shape)\n",
    "print('\\n\\nScaled Testing Set:')\n",
    "print('Scaled Testing Features:', X_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "de90c615",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Calculate the sigmoid of z.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    z : numpy array or float\n",
    "        Input value(s)\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    sigmoid(z) : numpy array or float\n",
    "        Sigmoid of the input\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
